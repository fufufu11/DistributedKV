# DistributedKV 项目学习手册
## 目录
- [1. 项目愿景](#1-项目愿景)
- [2. 核心架构：LSM-Tree 存储策略](#2-核心架构lsm-tree-存储策略)
    - [2.1 什么是 LSM-Tree？](#21-什么是-lsm-tree)
    - [2.2 为什么选择 LSM-Tree？](#22-为什么选择-lsm-tree)
- [3. 内存组件：MemTable 与跳表](#3-内存组件memtable-与跳表)
    - [3.1 MemTable 的作用](#31-memtable-的作用)
    - [3.2 为什么用跳表 (SkipList) 实现？](#32-为什么用跳表-skiplist-实现)
    - [3.3 跳表的基本原理](#33-跳表的基本原理)
    - [3.4 跳表核心操作图解](#34-跳表核心操作图解)
        - [3.4.1 结构总览](#341-结构总览)
        - [3.4.2 插入操作详解 (以插入 Key=8 为例)](#342-插入操作详解-以插入-key8-为例)
        - [3.4.3 复杂度分析](#343-复杂度分析)
        - [3.4.4 查找操作详解 (Search)](#344-查找操作详解-search)
        - [3.4.5 Search 的复杂度与工程注意事项](#345-search-的复杂度与工程注意事项)
        - [3.4.6 删除操作详解 (Remove)](#346-删除操作详解-remove)
        - [3.4.7 Remove 的时空复杂度与工程注意事项](#347-remove-的时空复杂度与工程注意事项)
    - [3.5 跳表单元测试（insert/search/remove）](#35-跳表单元测试insertsearchremove)
- [4. 持久化机制：WAL 预写日志](#4-持久化机制wal-预写日志)
    - [4.1 什么是 WAL？](#41-什么是-wal)
    - [4.2 为什么需要 WAL？](#42-为什么需要-wal)
    - [4.3 核心时序 (The Invariant)](#43-核心时序-the-invariant)
    - [4.4 崩溃恢复流程](#44-崩溃恢复流程)
    - [4.5 常见误区](#45-常见误区)
    - [4.6 可靠性分析：如果写失败了怎么办？](#46-可靠性分析如果写失败了怎么办)
    - [4.7 WAL 记录格式与编解码](#47-wal-记录格式与编解码)
        - [4.7.1 为什么需要编码？](#471-为什么需要编码)
        - [4.7.2 选型：定长 vs 变长？](#472-选型定长-vs-变长)
        - [4.7.3 物理布局 (On-Disk Layout)](#473-物理布局-on-disk-layout)
        - [4.7.4 为什么把 Checksum 放在最前面？](#474-为什么把-checksum-放在最前面)
        - [4.7.5 数据完整性校验：CRC32 算法详解](#475-数据完整性校验crc32-算法详解)
- [5. 分布式共识：Raft 协议](#5-分布式共识raft-协议)
- [6. 现代 C++ 语言特性与工程实践](#6-现代-c-语言特性与工程实践)
    - [6.1 RAII 与智能指针（概念与选型）](#61-raii-与智能指针概念与选型)
    - [6.2 现代 C++：std::optional 与 std::nullopt](#62-现代-cstdoptional-与-stdnullopt)
    - [6.3 C++17：结构化绑定（Structured Bindings）](#63-c17结构化绑定structured-bindings)
    - [6.4 C++ 关键字：explicit](#64-c-关键字explicit)
    - [6.5 C++17：std::filesystem::path 的 operator/](#65-c17stdfilesystempath-的-operator)
    - [6.6 C++ 关键字：inline（头文件与链接）](#66-c-关键字inline头文件与链接)
    - [6.7 C++ 类型转换：static_cast](#67-c-类型转换static_cast)
- [7. 构建系统与 CMake](#7-构建系统与-cmake)
    - [7.1 为什么选择 CMake + G++？](#71-为什么选择-cmake--g)
    - [7.2 本项目的构建工具链](#72-本项目的构建工具链)
    - [7.3 如何搭建开发环境 (Windows)](#73-如何搭建开发环境-windows)
    - [7.4 使用 build.ps1 构建](#74-使用-buildps1-构建)
    - [7.5 运行与验证](#75-运行与验证)
    - [7.6 VS Code 快捷键与集成](#76-vs-code-快捷键与集成)
- [8. 编码规范与文档化](#8-编码规范与文档化)
- [9. 学习路径建议](#9-学习路径建议)
- [10. 关键术语表](#10-关键术语表)
- [11. 项目计划（周级细化）](#11-项目计划周级细化)
    - [11.1 阶段 A：单机存储引擎（第 1–6 周）](#111-阶段-a单机存储引擎第-16-周)
    - [11.2 阶段 B：Raft 共识协议（第 7–12 周）](#112-阶段-braft-共识协议第-712-周)
    - [11.3 阶段 C：网络层与集成（第 13–16 周）](#113-阶段-c网络层与集成第-1316-周)
    - [11.4 阶段 D：工程化与展示（第 17–20 周）](#114-阶段-d工程化与展示第-1720-周)
    - [11.5 每周投入建议](#115-每周投入建议)
- [12. 测试与验证（详见独立文档）](#12-测试与验证详见独立文档)

---

## 1. 项目愿景与分布式系统基础

### 1.1 什么是分布式系统？
简单来说，分布式系统就是**一群独立的计算机，通过网络相互通信，并向用户表现得像一台单一的计算机一样**。

**核心特征：**
- **网络通信**：节点之间不共享内存，只能通过消息传递。
- **并发性**：多个节点同时运行。
- **缺乏全局时钟**：很难确定事件发生的绝对先后顺序。
- **部分故障**：集群中的某些节点可能挂掉或断网，但整个系统必须继续运行。

**为什么我们要搞分布式 KV？**
单机存储总有上限（磁盘容量、处理能力）。通过分布式，我们可以实现：
- **可扩展性 (Scalability)**：加机器就能存更多数据。
- **容错性 (Fault Tolerance)**：一台机器坏了，数据不丢，服务不投降。

---

## 2. 核心架构：[LSM-Tree](#9-关键术语表) 存储策略

### 2.1 什么是 [LSM-Tree](#8-关键术语表)？
[LSM-Tree](#8-关键术语表) (Log-Structured Merge-Tree) 不是一种单一的数据结构，而是一种**存储策略**。它主张“所有写操作都先写内存，攒够了再批量顺序写磁盘”。

**深度解析：顺序写 vs 随机写**
*   **随机写 (Random Write)**：类似于在图书馆找书，如果你要找 10 本分布在不同楼层的书，你需要不停地跑动、坐电梯、翻找，大部分时间浪费在“寻找”上。传统 B+ Tree 索引的就地更新就是随机写。
*   **顺序写 (Sequential Write)**：类似于在纸上一行一行写字。你不需要翻页或跳跃，笔尖始终在移动。
*   **性能差异**：在机械硬盘（HDD）上，顺序写比随机写快近千倍；在固态硬盘（SSD）上，顺序写也能显著减少磨损并提升吞吐量。

[LSM-Tree](#8-关键术语表) 的核心技巧就是：**通过内存缓冲区和后台[合并 (Compaction)](#8-关键术语表)，将应用程序的“随机写”操作，在磁盘层面转化为“顺序写”操作。**

### 2.2 为什么选择 [LSM-Tree](#8-关键术语表)？
1. **极致的写入性能**：所有的写入都是追加操作（Append-only），利用了磁盘最擅长的顺序 I/O。
2. **适应现代硬件**：对 SSD 极其友好，减少了随机小块写入带来的 GC 压力。
3. **分层管理**：通过后台的 [Compaction（合并）](#8-关键术语表) 过程，逐步清理旧数据，保持数据的有序性。

**推荐阅读**：
建议阅读《数据密集型应用系统设计 (DDIA)》第三章 "Storage and Retrieval"，其中详细对比了 B-Tree 和 [LSM-Tree](#8-关键术语表) 的优劣：
- **[写入放大 (Write Amplification)](#8-关键术语表)**：[LSM-Tree](#8-关键术语表) 通常具有更低的写入放大，适合写密集型负载。
- **顺序 I/O**：即使在 SSD 上，顺序写也能减少擦写次数，延长设备寿命。

---

## 3. 内存组件：MemTable 与跳表

### 3.1 MemTable 的作用
MemTable 是数据进入数据库的第一站。它驻留在内存中，负责暂存最近写入的数据，并保持数据的**有序性**，以便支持快速的范围查询。

### 3.2 为什么用跳表 (SkipList) 实现？
1. **实现简单**：相比红黑树或 AVL 树，跳表的实现逻辑更清晰，代码量通常只有平衡树的 1/3。
2. **并发友好**：在多线程环境下，跳表的无锁化或细粒度锁实现比平衡树更高效。LevelDB 和 RocksDB 选择跳表作为 MemTable 的核心原因之一，就是因为它只需要简单的 CAS 操作就能支持无锁并发读写，而平衡树的旋转操作在并发下极难维护。
3. **性能稳定**：平均查询时间复杂度为 $O(\log n)$，与平衡树相当。

### 3.3 跳表的基本原理
跳表通过在普通链表之上建立“多层索引”来实现快速跳转。
- **层级 (Level)**：每个节点被随机分配一个高度。
- **查找**：从最高层开始，如果当前层的下一个节点比目标大，则下沉到低一层继续查找。

### 3.4 跳表核心操作图解

为了更好地理解跳表，我们可以将其想象成**多层链表**或**地铁快慢车系统**。

#### 3.4.1 结构总览
假设跳表中存储了 `3, 6, 7, 9, 12`。
- **Level 0 (最底层)**：包含所有数据的普通链表（站站停）。
- **Level N (高层)**：快速通道，节点稀疏，跨度大。

```text
Level 2:  HEAD ---------------------> 7 --------------------------> NULL
Level 1:  HEAD ---------> 3 --------> 7 --------> 9 --------------> NULL
Level 0:  HEAD ---------> 3 -> 6 ---> 7 -> 9 ---> 12 -> 19 -------> NULL
```

#### 3.4.2 插入操作详解 (以插入 Key=8 为例)

插入操作的核心思想是：**先找位置，再织网**。

**步骤一：寻找前驱 (Find Predecessors)**
我们需要找到每一层中，目标 Key (8) 应该跟在谁后面。这些节点被称为“前驱节点”，我们用 `update[]` 数组记录它们。

1.  **Level 2**: `HEAD -> 7` (< 8)，`7 -> NULL` (停)。`update[2] = 7`
2.  **Level 1**: `7 -> 9` (> 8)，停。`update[1] = 7`
3.  **Level 0**: `7 -> 9` (> 8)，停。`update[0] = 7`

此时 `update[]` 指向每一层中 8 的前一个节点。

**步骤二：穿针引线 (Link Pointers)**
假设随机生成的新节点 8 的高度为 1 (包含 Level 0, 1)。我们需要将其插入到 `update` 节点之后。

核心逻辑：
1.  **新节点的下家** 接管 **前驱的下家**。
2.  **前驱的下家** 变更为 **新节点**。

```text
Level 1: ... 7 -> 8 (New) -> 9 ...  (8 接管了 9，7 指向了 8)
Level 0: ... 7 -> 8 (New) -> 9 ...
```

这样，新节点就安全地“挂”到了现有的网状结构中。

#### 3.4.3 复杂度分析

- **时间复杂度**：
    - **查找、插入、删除**：平均情况 $O(\log n)$，最坏情况 $O(n)$（极小概率退化为普通链表）。
    - 这里的 $\log n$ 来源于跳表的层数结构，类似于二分查找的排除过程。
- **空间复杂度**：
    - $O(n)$。虽然有额外的指针开销，但期望的指针总数是 $2n$（每层节点数减半级数求和）。

#### 3.4.4 查找操作详解 (Search)

查找操作的目标是：给定 `key`，在跳表中定位对应节点并返回其 `value`。跳表的查找可以理解为“高层快速定位 + 底层精确确认”。

**查找的关键直觉：**
- **Level 0** 一定包含所有节点，是“真实数据链”。
- 更高层（Level 1/2/...）是“稀疏索引层”，并不包含所有 key，只负责加速跳跃。

**查找步骤（从高到低）：**
1. 从 `head` 出发，站在最高层 `current_level - 1`。
2. 在当前层反复向右移动：只要 `forward[i]` 存在且 `forward[i]->key < key` 就前进。
3. 走不动时下沉一层，继续第 2 步。
4. 最终到达 Level 0 后，`current` 停在目标 key 的“前驱节点”上；候选节点是 `current->forward[0]`。
5. 若候选节点存在且 `candidate->key == key`，命中；否则未命中。

**为什么最终必须回到 Level 0 才能确认命中？**
- 因为索引层是抽样出来的节点集合，高层不保证存在目标 key；高层只能缩小范围，最终的等值判断以 Level 0 为准。

#### 3.4.5 Search 的复杂度与工程注意事项

- **时间复杂度**：
    - 平均 $O(\log n)$；最坏 $O(n)$。
    - 经验理解：每上升一层，节点数量期望减半，因此“向右移动的总次数”近似对数级。
- **空间复杂度**：$O(1)$（只使用少量指针变量，不需要 `update[]`）。
- **返回值语义**：
    - 推荐返回 `std::optional<V>` 来表达“可能未命中”，未命中时返回 `std::nullopt`，避免用特殊值造成歧义。
- **与 Insert 的关系**：
    - Insert 的第一阶段与 Search 完全同构：都是“从高层向右，再下沉”的定位过程。
    - Insert 额外需要 `update[]` 记录每层前驱用于穿针引线；Search 不修改结构，因此不需要 `update[]`。
- **Key 类型约束**：
    - 代码通常依赖 `K` 支持 `operator<` 与 `operator==`。
    - 若未来希望支持自定义排序规则，可在 `SkipList` 内引入比较器（Comparator）。
- **边界情况检查清单**：
    - 空表：`head->forward[0] == nullptr` 直接未命中。
    - 最小 key：高层几乎不右移，最终检查 `head->forward[0]`。
    - 最大 key：高层会频繁右移，最终落到最接近 key 的前驱节点。
    - 未命中：候选节点为空或 key 不相等。

#### 3.4.6 删除操作详解 (Remove)

删除操作的目标是：给定 `key`，将对应节点从跳表的各层链表中“断链”，使其在逻辑上不可达（后续 `search(key)` 未命中）。

**删除的关键直觉：**
- 删除与插入的第一阶段完全同构：都需要“从高层向右移动，再逐层下沉”，并在每一层记录目标 key 的前驱节点到 `update[]`。
- 删除本质是“拆网”：用 `update[]` 在每一层把指向目标节点的指针改为跨过它。

**删除步骤（与本项目实现对齐）：**
1. **构造 `update[]`（Find Predecessors）**：
   - 从 `head` 出发，站在最高层 `current_level - 1`。
   - 在每一层尽量向右走，直到 `forward[i]->key >= key` 或到达 NULL；此时 `current` 是该层前驱，记录 `update[i] = current`。
2. **定位候选目标节点 `target`**：
   - 候选节点位于 Level 0：`target = update[0]->forward[0]`。
   - 若 `target == nullptr` 或 `target->key != key`：说明 key 不存在，删除失败。
3. **逐层断链（Unlink Pointers）**：
   - 从 `i=0` 到 `i=current_level-1`：
     - 只有当 `update[i]->forward[i] == target` 时，才执行 `update[i]->forward[i] = target->forward[i]`。
   - 为什么需要这个判断：因为 `target` 的高度可能小于 `current_level`，更高层本来就不包含该节点；对这些层不应修改指针。
4. **收缩 `current_level`**：
   - 删除后如果最高层只剩 `head`（即 `head->forward[current_level - 1] == nullptr`），就应当将 `current_level` 逐层下调，直到该层非空或降到 1。
   - 这不会影响正确性，但能避免“空层”带来的额外遍历开销。

**3.4.6.1 update[] 与断链示意图**

为了把“断链”直观化，可以把删除理解为：在每一层把 `update[i]` 指向 `target` 的边，改成指向 `target` 的后继。

```text
假设要删除 key=8，且 Level 0/1 都包含该节点：

Before（断链前）
Level 1: ... 7 (update[1]) -> 8 (target) -> 9 -> ...
Level 0: ... 7 (update[0]) -> 8 (target) -> 9 -> ...

After（断链后）
Level 1: ... 7 (update[1]) -----------> 9 -> ...
Level 0: ... 7 (update[0]) -----------> 9 -> ...
```

```text
注意：target 的高度可能不足以出现在更高层。
例如 target 只出现在 Level 0 时：
Level 1: ... 7 (update[1]) -> 9 -> ...        （这一层没有 8）
Level 0: ... 7 (update[0]) -> 8 (target) -> 9 -> ...
因此断链时必须先判断：update[i]->forward[i] == target
```

**物理删除 vs Tombstone（联系 MemTable/LSM 的真实语义）**
- **物理删除（本任务做法）**：节点从链表断开后不可达；若同时释放内存，则该节点占用的内存也被回收。
- **Tombstone（LSM 常见做法）**：并不立即物理移除，而是写入“删除标记”，后续通过 Compaction 清理；这样才能正确处理“删除覆盖旧值”的语义，并避免跨层文件间的歧义。

**本项目的内存所有权模型（工程注意事项）**
- forward 中使用的是裸指针，但节点由 `nodes_storage`（`std::unique_ptr` 容器）统一持有。
- 因此删除至少需要完成“断链”（保证逻辑不可达）；若希望回收内存，需要同时从 `nodes_storage` 中擦除对应 `unique_ptr`。

**阶段策略（本项目当前选择）**
- 当前阶段（仅 MemTable/跳表）：先实现并验收物理删除（断链 + 从 `nodes_storage` 擦除以回收内存）。
- 后续阶段（引入 SSTable 并打通 Get/Compaction）：删除语义迁移为 Tombstone，并由 Compaction 负责清理旧版本与删除标记。

#### 3.4.7 Remove 的时空复杂度与工程注意事项

- **时间复杂度**：
    - 平均 $O(\log n)$：构造 `update[]` 需要一次“从高到低”的查找；断链最多改动 `current_level` 条指针；收缩层级最多下降到 1。
    - 最坏 $O(n)$：当跳表退化（极端概率或数据/随机性导致接近链表）时，定位前驱会退化为线性扫描。
- **额外空间复杂度**：
    - $O(\text{max\_level})$：`update[]` 需要为每一层保存一个前驱指针。
    - 其余为 $O(1)$：少量临时指针变量。
- **工程注意事项**：
    - 断链时必须检查 `update[i]->forward[i] == target`，避免访问 `target->forward[i]` 的越界风险（target 高度不足时更高层不存在该指针）。
    - 删除后收缩 `current_level` 能减少后续 `search/insert/remove` 在空层的无效遍历。
    - 本项目用 `nodes_storage`（`std::vector<std::unique_ptr<Node<...>>>`）持有节点：若你选择“真物理删除并回收内存”，需要从该容器中擦除；该擦除是线性查找 + `erase`，单次可能是 $O(n)$ 的移动成本（作为教学实现可以接受，后续可再工程化优化）。

### 3.5 跳表单元测试（insert/search/remove）

在本项目中，跳表的单元测试位于：
- `tests/skiplist_test.cpp`

当前测试范围聚焦于 `insert/search/remove` 的基础正确性与“多层路径是否能走通”。为了让测试稳定可复现（不被随机层数干扰），测试中刻意使用了两种极端概率：
- `prob = 0.0f`：`random_level()` 恒为 1，跳表退化为单层有序链表，便于验证最基础的插入与查询
- `prob = 1.0f`：节点层数恒增长到 `max_level`，用于覆盖扩层与多层 `forward` 指针维护路径

#### 3.5.1 当前已实现用例覆盖点（14 个）

- 空表查找应未命中
- 单条插入后应命中；未插入 key 仍未命中
- 重复插入同 key 的语义：更新 value（以当前实现为准）
- 顺序批量插入后逐个查询应全部命中且值正确
- 乱序插入后逐个查询应全部命中且值正确
- 强制全升层（`prob=1.0f`）下，插入与查询应正确
- `std::string` 作为 key 的模板实例化与比较路径可用
- 空表删除：`remove` 返回 false
- 删除不存在的 key：`remove` 返回 false，且表结构不应被破坏（已存在 key 仍可查）
- 插入→删除→查找：被删 key 查不到；未删 key 仍可查
- 删除后再插入同 key：应能重新插入并查到新 value
- 删除边界 key（最小/最大）：结构仍正确，未删 key 仍可查
- 随机删除一半：已删查不到、未删查得到
- （多层断链）`prob=1.0f` 下删除若干 key：已删不可查、未删可查

#### 3.5.2 remove 覆盖点（已实现）

为了补齐删除逻辑的正确性，本项目已覆盖以下路径（优先固定 `prob=0.0f` 让结构退化为单层，便于稳定复现）：

- 空表删除：`remove` 返回 false
- 删除不存在的 key：`remove` 返回 false，且表结构不应被破坏（已存在 key 仍可查）。
- 插入→删除→查找：被删 key 查不到；未删 key 仍可查。
- 删除后再插入同 key：应能重新插入并查到新 value。
- 删除边界 key（最小/最大）：结构仍正确。
- 随机删除一半：插入 `[0,n)`，打乱后删除前半；验证已删查不到、未删查得到。
- 使用 `prob=1.0f` 覆盖多层断链路径，验证多层 forward 的一致性。

#### 3.5.3 验收结果记录

- 运行方式：构建后执行 `ctest --output-on-failure`
- 最近一次结果：14/14 tests passed（包含 remove 相关用例）


---

## 4. 持久化机制：WAL 预写日志

### 4.1 什么是 WAL？
**WAL (Write-Ahead Log)** 就是数据库的“飞行记录仪”或“流水账”。

- **定义**：在将数据真正修改到内存（MemTable）之前，先把这次操作记录到磁盘上的日志文件中。
- **核心思想**：先记账，再干活。

### 4.2 为什么需要 WAL？
在 LSM-Tree 架构中：
1. **内存易失**：MemTable 驻留在内存，一旦进程崩溃或断电，数据就会瞬间丢失。
2. **SSTable 滞后**：虽然数据最终会 Flush 到 SSTable（磁盘），但这是一个批量、低频的后台动作。
3. **补救措施**：WAL 通过“顺序追加写”的方式，以极低的磁盘开销，为内存数据提供了一份实时的持久化备份。

### 4.3 核心时序 (The Invariant)
为了保证不丢数据，每次写入操作（Put/Delete）必须严格遵守以下顺序：

1.  **Append**：将操作封装成日志条目，追加写入 WAL 文件缓存。
2.  **Sync**：调用 `fsync` 强行将文件缓存刷入磁盘介质（落盘）。
3.  **Apply**：将操作应用到内存中的 MemTable。
4.  **Ack**：向客户端返回“成功”。

**反例**：如果先写 MemTable 再写 WAL，那么在两者之间崩溃时，客户端认为成功了，但重启后数据却丢了（因为 WAL 没记下来）。

### 4.4 崩溃恢复流程
当数据库重启时：
1.  **Open**：打开 WAL 文件。
2.  **Replay**：从头到尾顺序读取每条日志。
3.  **Rebuild**：将读到的操作重新 Apply 到 MemTable 中。
4.  **Stop**：如果读到文件尾部发现半条记录（Checksum 不匹配或长度不足），说明上次是异常崩溃，直接截断并停止，认为恢复完成。

### 4.5 常见误区
- **Flush != Sync**：
    - `flush` 只是把数据从用户态拷贝到内核态（OS Cache），断电仍会丢。
    - `fsync` 才是逼迫硬盘把数据写在磁性介质上。
- **WAL != Raft Log**：
    - WAL 是单机存储引擎的持久化手段。
    - Raft Log 是分布式系统多节点间达成一致性的手段。
    - 在完整系统中，两者通常并存（或者合并实现）。

### 4.6 可靠性分析：如果写失败了怎么办？
**没有 100% 成功的 I/O**。WAL 设计的核心不在于“永不失败”，而在于“失败后不坏事”。

**场景 1：写入时系统报错 (System Call Failures)**
- **现象**：`write` 或 `fsync` 返回错误（如磁盘已满、权限不足、文件句柄耗尽）。
- **应对**：立即向客户端返回 Error。
- **禁忌**：**绝对禁止**在 WAL 写失败的情况下更新 MemTable。必须保证“内存有数据”蕴含“磁盘有记录”。

**场景 2：写了一半断电 (Partial Writes)**
- **现象**：操作系统或硬件在 `write()` 数据中途断电，导致日志文件尾部只有半条记录（例如只写了 Header，没写 Body）。
- **应对**：**Checksum 校验** + **长度检查**。
- **恢复**：启动重放时，一旦发现尾部记录 Checksum 不匹配或长度不完整，直接**丢弃该条及之后的记录（Truncate）**，并认为这是最后一次未完成的事务。这是符合 ACID 原子性的。

**场景 3：磁盘静默损坏 (Bit Rot)**
- **现象**：磁盘老化导致中间某条旧日志的比特位翻转。
- **应对**：全量 Checksum 校验。
- **恢复**：若在日志**中间**发现损坏，这是一个严重的数据丢失事件。单机引擎通常选择**报错并拒绝启动**，提示人工介入；而在分布式系统（如 Raft）中，可以通过其他节点的副本来修复。

### 4.7 WAL 记录格式与编解码

#### 4.7.1 为什么需要编码？
磁盘文件是字节流（Byte Stream），而内存对象是结构化的（Struct/Class）。我们需要定义一种协议，将 Key/Value/Type 转换为紧凑的字节序列。

#### 4.7.2 选型：定长 vs 变长？
在设计存储格式时，常见的两种流派：

1.  **纯定长 (Fixed Length)**：
    *   例如：每个 Key 预留 256 字节。
    *   **缺点**：**空间浪费严重**。短 Key 浪费空间，长 Key 会被截断。
2.  **纯变长 (Variable Length / Varint)**：
    *   例如：Protobuf 的 Varint 编码（用最高位表示是否结束）。
    *   **优点**：极致紧凑（数字 5 只占 1 字节）。
    *   **缺点**：实现复杂，且解码需要位运算，消耗 CPU。
3.  **混合模式：定长头部 + 变长载荷 (Fixed Header + Variable Payload)**（**本项目选用**）：
    *   **Header**：固定长度（如 13 字节），记录 Type, KeyLen, ValueLen, Checksum。
    *   **Payload**：紧跟 Header，存储 Key 和 Value 的原始内容。
    *   **优点**：**解析极快**（读 Header 就知道后面该读多少），实现简单（`memcpy` 即可），兼顾了灵活性。

#### 4.7.3 物理布局 (On-Disk Layout)
本项目采用的 WAL 记录格式如下（紧凑排列，无内存对齐填充）：

```text
+----------------+----------------+----------------+----------------+----------------+-----------------+
| Checksum (4B)  | Key Len (4B)   | Value Len (4B) | Type (1B)      | Key Payload    | Value Payload   |
+----------------+----------------+----------------+----------------+----------------+-----------------+
| CRC32 of rest  | Length of Key  | Length of Value| 0=Put, 1=Del   | "my_key"       | "my_value"      |
+----------------+----------------+----------------+----------------+----------------+-----------------+
```
- **Checksum**：使用 CRC32 算法计算 `Type + KeyLen + ValueLen + Key + Value` 的校验和。读取时重新计算并比对。
- **Type**：枚举值，标识操作类型（Put / Delete）。
- **Key/Value Len**：指定后续 Payload 的字节数。

#### 4.7.4 为什么把 Checksum 放在最前面？
- 方便读取：先读 4 字节 Checksum，再读 Header 其余部分。
- 也可以放在最后，但放在最前面在处理“定长 Header”时代码写起来更统一（Header = 13 Bytes）。

#### 4.7.5 数据完整性校验：CRC32 算法详解

**1. 什么是 CRC32？**
CRC (Cyclic Redundancy Check) 是一种利用多项式除法检测数据错误的算法。CRC32 输出一个 32 位的整数。它的特点是：
- **对突发错误敏感**：能很好地检测磁盘坏道或网络传输中连续的比特位翻转。
- **计算速度快**：基于位运算，适合实时计算。

**2. 代码实现原理解析**
你可能会在代码中看到这样的实现：

```cpp
// 逐位计算 (Bit-wise) 实现
inline uint32_t crc32(const char* data, size_t length) {
    uint32_t crc = 0xFFFFFFFF;  // 1. 初始值
    for (size_t i = 0; i < length; ++i) {
        uint8_t byte = static_cast<uint8_t>(data[i]);
        crc = crc ^ byte;       // 2. 载入新字节
        for (int j = 0; j < 8; ++j) {
            uint32_t mask = -(crc & 1);
            // 3. 多项式除法核心：0xEDB88320
            crc = (crc >> 1) ^ (0xEDB88320 & mask);
        }
    }
    return ~crc;                // 4. 结果取反
}
```

**2.1 逐行解释（按代码顺序）**
把 `crc` 想象成一个 32 位的“滚动指纹寄存器”。我们每次读入一个字节，就把它混进寄存器，然后用 8 次循环把这个字节的 8 个 bit 按规则“处理掉”。每一步都在把输入的信息扩散到整个 32 位里。

1. `inline uint32_t crc32(const char* data, size_t length)`：函数输入是一段字节序列 `data[0..length)`，输出是 32 位校验值。
2. `uint32_t crc = 0xFFFFFFFF;`：初始化寄存器为全 1（这是 CRC32 的常见标准做法之一）。
3. `for (size_t i = 0; i < length; ++i)`：按字节遍历输入数据。
4. `uint8_t byte = static_cast<uint8_t>(data[i]);`：把 `char` 安全转换为 0..255 的无符号字节，避免 `char` 为有符号类型时出现负值扩展。
5. `crc = crc ^ byte;`：把当前字节“混入”寄存器的最低 8 位（先喂进去，后面 8 次循环会把影响扩散到更高位）。
6. `for (int j = 0; j < 8; ++j)`：对刚混入的这个字节，逐 bit 处理 8 次。
7. `uint32_t mask = -(crc & 1);`：无分支技巧，只看寄存器最低位是否为 1：
   - 若 `crc & 1 == 1`，则 `mask = 0xFFFFFFFF`
   - 若 `crc & 1 == 0`，则 `mask = 0x00000000`
8. `crc = (crc >> 1) ^ (0xEDB88320 & mask);`：核心规则：
   - `crc >> 1`：右移 1 位，相当于“处理掉”最低位；
   - `0xEDB88320`：CRC32 的固定多项式常量（你可以先把它当作“规则配方”）；
   - 结合第 7 行，等价于：
     - 若最低位为 1：`crc = (crc >> 1) ^ 0xEDB88320`
     - 若最低位为 0：`crc = (crc >> 1)`
9. `return ~crc;`：最终取反（标准 CRC32 的常见收尾步骤之一）。

**2.2 关键直觉：第 7/8 行在做什么？**
第 7/8 行其实就是把下面这个 if/else 写成“没有分支的等价形式”（更快，也更像底层算法实现）：

```text
if (crc 的最低位是 1) {
    crc = (crc >> 1) ^ 0xEDB88320;
} else {
    crc = (crc >> 1);
}
```

你可以用两个极小例子来理解 `mask`（不需要算完整 CRC，只看这一轮逻辑）：
- 若当前 `crc` 最低位是 1：`crc & 1 = 1`，`mask = 0xFFFFFFFF`，所以 `(0xEDB88320 & mask) = 0xEDB88320`，会触发异或多项式。
- 若当前 `crc` 最低位是 0：`crc & 1 = 0`，`mask = 0`，所以 `(0xEDB88320 & mask) = 0`，这一轮只右移，不异或多项式。

**2.3 为什么初始值常用 `0xFFFFFFFF`（用“前导 0”举例）**
如果初始值设成 `0`，并且数据开头是 `0x00` 字节，那么 CRC 寄存器会“很容易”保持 0，前导 0 对 CRC 的影响会变得很弱：
- 初始 `crc = 0`
- 读入 `byte = 0x00` 后：`crc ^= byte` 仍然是 0
- 内层 8 次循环：`crc` 的最低位一直是 0，所以每次都只右移，结果仍然是 0

而用 `0xFFFFFFFF` 初始化，即便第一个字节是 `0x00`，`crc` 一开始也不为 0，会在右移和条件异或中不断变化，让“前导 0”也能更充分地影响最终 CRC。

**3. 工程决策：为什么不用查表法？**
你可能会问：“既然这个逐位循环效率低，为什么不直接用查表法（Table-based）？”

- **查表法 (Table-based)**：
    - **原理**：预先算好 256 种字节对应的 CRC 变化，存入一个 `uint32_t table[256]` 数组。计算时一次处理一个字节，无内层循环。
    - **优点**：速度快（通常快 8-10 倍）。
    - **缺点**：需要硬编码或生成一个 1KB 的静态数组，增加代码体积，降低可读性。
- **逐位法 (Bit-wise)**：
    - **优点**：代码极简（10 行），无需外部依赖，逻辑透明。
    - **缺点**：慢。
- **当前选型理由**：
    - **瓶颈不在 CPU**：在 WAL 写入场景中，真正的瓶颈是**磁盘 I/O (fsync)**。CRC 计算带来的微秒级延迟相对于毫秒级的磁盘落盘几乎可以忽略不计。
    - **教学优先**：在起步阶段，理解原理比极致性能更重要。
    - **优化空间**：这恰好是一个绝佳的后续优化点。当我们后续进行 Benchmark 发现热点时，再亲手将其替换为查表法，会有更深刻的体会。

**4. 通俗类比：除法取余**
如果你觉得多项式除法太抽象，可以把它想象成小学的“除法取余数”。

*   **发送方**：
    1.  把数据看作一个巨大的数字（比如 `12345`）。
    2.  选定一个固定的除数（多项式，比如 `7`）。
    3.  计算 `12345 ÷ 7 = 1763 余 4`。
    4.  发送方把数据 `12345` 和余数 `4`（即 CRC）一起发出去。
*   **接收方**：
    1.  收到数据 `12345` 和余数 `4`。
    2.  自己算一遍：`12345 ÷ 7`，发现余数也是 `4`。
    3.  **结论**：数据没变，校验通过。
    4.  *如果数据传输中变成了 `12346`，计算 `12346 ÷ 7` 余数是 `5`，跟收到的 `4` 对不上，说明出错了。*

在计算机中，我们用的是二进制的除法（模 2 除法，即异或操作），但原理一模一样。

**5. 具体在哪里用到？**
在我们的分布式 KV 系统中，CRC 会像“安检员”一样出现在每个数据流动的关口：

1.  **WAL (当前任务)**：
    *   **写入时**：每条日志（Put/Del）末尾都附带 CRC。
    *   **作用**：防止磁盘坏道导致比特位翻转；防止写了一半断电（只写了头没写尾，CRC 肯定对不上）。
2.  **SSTable (磁盘文件)**：
    *   **存储时**：每个数据块（Block）后面都跟一个 CRC。
    *   **作用**：防止长期存储后磁盘静默腐烂（Bit Rot）。
3.  **Snapshot (快照)**：
    *   **传输时**：Leader 把快照发给 Follower 时，整个文件算一个 CRC。
    *   **作用**：防止网络传输丢包或乱序导致文件损坏。
4.  **RPC 通信 (Raft)**：
    *   虽然 TCP 有校验，但应用层通常会再加一层 CRC 以防止复杂的内存错误或中间件篡改。

---

## 5. 分布式共识：[Raft](#8-关键术语表) 协议
[Raft](#8-关键术语表) 是目前工业界最流行的分布式一致性算法。它将复杂的问题分解为三个子问题：
1. **Leader 选举**：集群中始终有一个 Leader 负责处理所有客户端请求。
2. **日志复制**：Leader 将操作记录同步给 Follower，只有大多数节点确认后，数据才算“提交”。
3. **安全性**：通过[任期 (Term)](#8-关键术语表)和日志索引 (Index) 保证历史数据不被覆盖。

---

## 6. 现代 C++ 语言特性与工程实践

### 6.1 RAII 与智能指针（概念与选型）
**RAII** (Resource Acquisition Is Initialization)，即“资源获取即初始化”。它是 C++ 语言中最核心的编程思想之一。

**核心逻辑：**
1. **获取资源即初始化**：在对象的**构造函数**中获取资源（如申请内存、打开文件、加锁）。
2. **释放资源即析构**：在对象的**析构函数**中释放资源。
3. **绑定生命周期**：将资源的生命周期与局部对象的生命周期绑定。只要对象被销毁（如离开作用域），资源就会自动释放。

**为什么它很伟大？**
- **防泄漏**：即使函数中间抛出异常或提前 `return`，析构函数也一定会被调用。
- **自动化**：程序员不再需要手动写 `delete`、`fclose()` 或 `unlock()`，减少了心智负担。

**本项目中的应用：**
- **智能指针**：`std::unique_ptr` 封装了裸指针的 `new/delete`。
- **文件流**：`std::ofstream` 离开作用域自动关闭文件。
- **并发锁**：`std::lock_guard` 离开作用域自动释放互斥锁（后续 Raft 实现中会大量使用）。

---

**三大智能指针详解**

**1. `std::unique_ptr`（独占所有权）**
- **核心思想**：同一时间只能有一个指针拥有该对象的所有权。
- **特点**：
    - 不可拷贝，只能移动（`std::move`）。
    - 几乎没有性能开销（与裸指针性能一致）。
- **什么是“移动” (Move)？**
    - **通俗理解**：拷贝是“复印”，移动是“过户”。
    - **底层原理**：移动不会产生新的数据副本。它只是把原指针内部指向内存的地址“偷”过来，给新指针，然后把原指针置为空（nullptr）。
    - **为什么要移动？**：性能极高。比如一个管理 1GB 内存的对象，拷贝需要复制 1GB 数据，而移动只需要复制一个 8 字节的地址指针。
    - **语法**：使用 `std::move(ptr)` 将左值强制转换为右值引用，从而触发移动构造函数。
- **适用场景**：
    - **默认选择**：当你需要一个局部的、生命周期明确的对象时。
    - **容器管理**：如本项目的 `nodes_storage`，由 `SkipList` 独占所有节点的所有权。

**2. `std::shared_ptr`（共享所有权）**
- **核心思想**：通过**引用计数**实现多个指针共享同一个对象。
- **缺点：循环引用（Circular Reference）**：
    - **为什么不得不互相引用？**
        - **父子关系**：在 GUI 框架中，父窗口拥有子按钮（`shared_ptr`），但子按钮有时需要回调父窗口的方法（如果也用 `shared_ptr`，就循环了）。
        - **双向链表**：前驱节点指向后继，后继也指向前驱。
        - **观察者模式**：被观察者（Subject）通知观察者，观察者（Observer）有时也需要取消订阅（反向引用）。
    - **后果**：它们的引用计数永远至少为 1，导致即便外部已经没有任何指针指向它们，它们也永远不会被销毁。这就是内存泄漏！

**3. `std::weak_ptr`（弱引用）**
- **核心思想**：它是 `shared_ptr` 的“观察者”。它指向对象，但**不增加引用计数**。
- **为什么使用前必须调用 `lock()`？**
    - **安全性保证**：`weak_ptr` 不拥有对象，它指向的对象可能随时被其他线程释放。
    - **原子操作**：`lock()` 是一个原子操作。它会检查对象是否还活着：
        - 如果还活着，它会把引用计数 **+1**，并返回一个临时的 `shared_ptr`。只要这个 `shared_ptr` 还在，对象就绝对不会在你处理逻辑时被删掉。
        - 如果对象已经没了，它返回一个空的 `shared_ptr`。
    - **如果不 lock 而是直接使用会怎样？**：你可能在第一行代码判断它还活着，但在第二行真正访问成员时，对象刚好被删了，程序会直接崩溃（段错误）。
- **如何配合使用？**
    - **打破循环**：在双向关系中，一方持强引用（`shared_ptr`），另一方持弱引用（`weak_ptr`）。
    - **代码示例**：
        ```cpp
        std::weak_ptr<int> wp = sp; // sp 是 shared_ptr
        // wp.use_count() 不会增加
        if (auto locked_sp = wp.lock()) {
            // 此时 locked_sp 是一个新的 shared_ptr，计数 +1
            // 即使外部的 sp 被销毁，locked_sp 也能保证对象在这里是安全的
            std::cout << *locked_sp << std::endl;
        } // 函数结束，locked_sp 销毁，计数 -1
        ```

**决策指南：该选哪种？**

| 场景 | 推荐方案 | 理由 |
| :--- | :--- | :--- |
| **大部分情况** | `std::unique_ptr` | 性能最优，职责最清晰。 |
| **需要多个拥有者** | `std::shared_ptr` | 自动处理复杂的生命周期共享。 |
| **打破循环引用** | `std::weak_ptr` | 防止 A 引用 B，B 又引用 A 导致的永久不释放。 |
| **底层性能敏感/算法实现** | 裸指针 (`T*`) | 仅用于**观察**（不拥有所有权），如跳表节点间的 `forward` 链接。 |

### 6.2 现代 C++：std::optional 与 std::nullopt

在 C++ 中，“函数是否有返回结果”经常是业务语义的一部分。例如跳表的 `search(key)`：可能命中，也可能未命中。`std::optional` 用类型系统把这种“有/无”的语义表达出来。

#### 6.2.1 `std::optional<T>`：可能有值的返回类型

- **定义**：`std::optional<T>` 表示“一个可能存在、也可能不存在的 `T` 值”。它要么装着一个 `T`，要么为空。
- **典型场景**：
    - 查找：命中返回值，未命中返回空。
    - 解析：解析成功返回结果，失败返回空。
    - 缓存：命中返回对象，未命中返回空。
- **为什么不直接返回 `T`？**
    - 如果返回 `T`，未命中时通常只能返回一个“特殊值”（例如 `-1`、空字符串），但特殊值可能与合法值冲突，产生歧义。
    - `optional` 让调用者必须显式处理“无值”分支，可读性更强。

#### 6.2.2 `std::nullopt`：表示“空的 optional”

- **含义**：`std::nullopt` 是一个标记量，用来表示“这里没有值”。常用于构造/返回一个空的 `std::optional<T>`。
- **示例**：`return std::nullopt;` 表示“未找到 / 不存在 / 没有结果”。

#### 6.2.3 常用 API（写测试时会频繁用到）

- 判断是否有值：
    - `if (opt) { ... }`
    - `if (opt.has_value()) { ... }`
- 取值（必须确保有值）：
    - `*opt`
    - `opt.value()`（无值会抛异常）
- 带默认值取值：
    - `opt.value_or(default_value)`（无值时返回默认值，不抛异常）

#### 6.2.4 在本项目中的应用：跳表 Search

在本项目中，`SkipList::search` 返回 `std::optional<V>`：
- 命中：返回包含 `value` 的 `optional`。
- 未命中：返回 `std::nullopt`。

这样调用者可以清晰地区分“找到了一个值”和“没找到”，而无需约定一个可能冲突的特殊返回值。

### 6.3 C++17：结构化绑定（Structured Bindings）

结构化绑定（Structured Bindings）是 C++17 引入的一种语法糖，用于把“可拆分”的对象（如 `std::pair` / `std::tuple` / `struct` / 数组）一次性拆成多个变量，提升可读性。

#### 6.3.1 最常见的形式：拆 `std::pair`

```cpp
std::pair<int, std::string> p{1, "one"};
auto [k, v] = p;  // k 是 int，v 是 std::string（注意：这里是拷贝/移动）
```

对应到我们的测试代码：

```cpp
for (const auto& [k, val] : expected) {
    // ...
}
```

这里 `expected` 是 `std::unordered_map<int, std::string>`，它遍历时得到的元素类型本质上是 `std::pair<const int, std::string>`，结构化绑定把它拆成：
- `k`：key（类型是 `const int`，因此不能修改 key）
- `val`：value（类型是 `std::string`，但由于外层是 `const auto&`，因此此处 `val` 也是只读引用）

#### 6.3.2 `auto` / `auto&` / `const auto&` 的区别（非常关键）

- `auto [a, b] = obj;`
  - 生成两个新变量，通常会发生拷贝/移动。
  - 修改 `a/b` 不会影响 `obj`。
- `auto& [a, b] = obj;`
  - 绑定为引用，`a/b` 直接引用 `obj` 里的成员。
  - 修改 `b` 会影响原对象（对 `map/unordered_map` 而言，`a` 是 key，通常是 `const` 不能改）。
- `const auto& [a, b] = obj;`
  - 只读引用绑定，常用于遍历容器时避免拷贝，同时保证不修改元素。

在范围 for 中我们写 `for (const auto& [k, val] : expected)` 的效果是：
- 不拷贝 map 里的元素（更高效）
- 不允许在循环中意外改动 key/value（更安全）

#### 6.3.3 还能拆哪些类型？

- 拆 `std::tuple`：
  - `auto [x, y, z] = std::tuple{1, 2.0, "hi"};`
- 拆简单 `struct`（需要 public 成员）：
  - `struct S { int x; int y; }; S s{1,2}; auto [x, y] = s;`
- 拆数组：
  - `int a[2] = {1,2}; auto [x, y] = a;`

#### 6.3.4 记一个避免踩坑的规则

如果你想“在遍历时修改容器元素的 value”，应写：

```cpp
for (auto& [k, v] : mp) {
    v += 1;
}
```

而不是 `auto [k, v]`，因为后者会把元素拷贝出来，你修改的是副本。

---

### 6.4 C++ 关键字：explicit

`explicit` 用来**禁止隐式类型转换**，最常见的用途是标注“单参数构造函数”和“类型转换运算符”，避免出现不经意的自动转换导致逻辑歧义。

**核心作用：**
- 防止“把一个类型偷偷当成另一个类型”。
- 让构造函数必须被显式调用，代码意图更清晰。

**典型场景：**
- 单参数构造函数用于表达“强类型语义”时，建议加 `explicit`。
- 自定义类型转换运算符（`operator T()`）通常也加 `explicit`，避免隐式参与重载决议。

**直觉记忆：**
- 没有 `explicit`：编译器可以“帮你猜”怎么转。
- 有了 `explicit`：你必须“明确写出”转换动作。

**代码示例：**

```cpp
struct Bytes {
    // explicit 禁止了 "int -> Bytes" 的隐式转换
    explicit Bytes(int size) : size_(size) {}
    int size_;
};

void send_data(const Bytes& b) { /* ... */ }

int main() {
    int packet_size = 1024;
    
    // [编译错误] 
    // send_data(packet_size); 
    // 错误原因：编译器不再允许把 int 自动转成 Bytes
    
    // [正确] 显式构造
    send_data(Bytes(packet_size)); 
}
```

---

### 6.5 C++17：std::filesystem::path 的 operator/

`std::filesystem::path` 重载了 `/` 运算符，用来**拼接路径**，返回一个新的 `path`。这不是数学除法，而是“路径拼接语义”。

在代码里出现：
- `wal_path_ = data_dir_ / "wal.log";`

含义是：以 `data_dir_` 为基础目录，在其后拼接文件名 `wal.log`，得到最终的 WAL 文件路径。

**关键点：**
- `data_dir_` 通常是 `std::filesystem::path` 类型。
- 右侧可以是 `const char*` / `std::string` / `path`，会被转换为 `path` 再拼接。
- 拼接时会使用系统的路径分隔符（Windows 下是 `\`，但内部可统一用 `/` 表达，输出时自动转换）。

**注意边界：**
- 如果右侧是**绝对路径**，它会**覆盖**左侧的内容（等价于“从根开始”），这点在拼接用户输入路径时要特别小心。

---

### 6.6 C++ 关键字：inline（头文件与链接）

很多初学者认为 `inline` 只是为了“性能”，其实在现代 C++ 工程中，它更重要的作用是**解决头文件链接问题**。

#### 6.6.1 什么是“内联展开” (Inline Expansion)？
“内联展开”是编译器的一种优化手段：**把函数调用直接替换为函数体本身**，从而省去函数调用的开销（压栈、跳转、返回）。

**图解对比：**

假设有这样一个函数：
```cpp
int add(int a, int b) { return a + b; }
```

- **普通调用 (No Inline)**：
  ```cpp
  int x = add(1, 2);
  // 机器码逻辑：
  // 1. 把 1, 2 压入寄存器/栈
  // 2. CALL add 地址
  // 3. (跳转到 add) 执行加法，把结果放回返回值寄存器
  // 4. RET 返回
  ```
- **内联展开 (Inlined)**：
  ```cpp
  int x = add(1, 2);
  // 机器码逻辑：
  // 直接生成加法指令，没有 CALL/RET
  // int x = 1 + 2; 
  ```

**注意：** `inline` 关键字只是给编译器的**建议**。
- 如果函数太复杂（有循环、递归），编译器会无视 `inline`，依然生成 CALL。
- 即使没写 `inline`，只要开启 `-O2`，编译器也会自动把小函数内联。

#### 6.6.2 为什么头文件里的函数要加 inline？
这是 `inline` 在工程中更关键的用途：**One Definition Rule (ODR) 的豁免权**。

**问题场景：**
假设你在 `utils.h` 里写了一个函数**定义**（不仅是声明）：
```cpp
// utils.h
int max_val(int a, int b) { return a > b ? a : b; }
```
如果 `A.cpp` 和 `B.cpp` 都 `#include "utils.h"`：
1. `A.cpp` 编译生成 `A.o`，里面有一个 `max_val` 的符号。
2. `B.cpp` 编译生成 `B.o`，里面也有一个 `max_val` 的符号。
3. **链接阶段 (Linker)**：链接器发现两个 `.o` 里都有 `max_val`，就会报 **"multiple definition" (重定义错误)**。

**解决方案：**
加上 `inline`：
```cpp
// utils.h
inline int max_val(int a, int b) { return a > b ? a : b; }
```
- 含义变了：告诉链接器，“这个函数可能在多个单元里被定义多次，但它们都是同一个东西，请忽略重复，最终只保留一份（或都内联掉）”。
- **结论**：**只要你在头文件 (.h) 里写函数体，就必须加 `inline`**（类内定义的成员函数默认隐含 inline，所以不用显式写）。

#### 6.6.3 总结
- **性能视角**：`inline` 只是建议，能不能展开看编译器心情。
- **链接视角**：`inline` 是头文件写函数实现的**必须通行证**，防止重定义报错。
- **本项目应用**：`wal_record.h` 中的 `crc32` 是在头文件直接实现的工具函数，所以必须加 `inline`。

---

### 6.7 C++ 类型转换：static_cast

C++ 提供了四种显式类型转换操作符（`static_cast`, `dynamic_cast`, `const_cast`, `reinterpret_cast`），其中 `static_cast` 是使用最频繁、最推荐的“常规武器”。

#### 6.7.1 什么是 static_cast？
它是 C++ 用于进行**编译时检查**的显式类型转换。
- **适用场景**：编译器认为“合理”的转换（如 `int` 转 `float`，`void*` 转具体指针，子类转父类）。
- **不适用场景**：完全无关的类型转换（如 `int*` 转 `float*`，这需要 `reinterpret_cast`）。

#### 6.7.2 为什么要取代 C 风格转换？
你可能习惯写 C 风格的 `(type)value`，例如 `(int)3.14`。但在 C++ 中，我们强烈建议改用 `static_cast<int>(3.14)`，理由如下：

1.  **安全性（Safety）**：
    - C 风格转换太暴力，它会尝试各种手段（包括 `reinterpret_cast` 的能力）强行转换，容易把无关的指针乱转，导致运行时崩溃。
    - `static_cast` 会在编译期检查类型兼容性，如果不合理直接报错。
2.  **可搜索性（Searchability）**：
    - 在几万行代码里找“哪里把 float 转成了 int”？搜索 `(` 是不可能的。
    - 搜索 `static_cast` 可以瞬间定位所有显式转换，便于代码审计。

#### 6.7.3 实战场景：防止符号扩展 bug
在 `wal_record.h` 的 CRC 计算中，我们用到了：
```cpp
uint8_t byte = static_cast<uint8_t>(data[i]);
```
**为什么要转？**
- `data` 是 `const char*`。在很多平台上，`char` 是**有符号的 (signed)**，范围是 -128 到 127。
- 假设 `data[i]` 的二进制是 `11111111`（即 -1）。

**图解对比：符号扩展的破坏力**
假设当前 `crc` 为 `0x00000000`（即使初始值为 0，也无法幸免），我们需要异或这个 `0xFF` 字节。

1.  **正确情况 (static_cast<uint8_t>)**：
    - `0xFF` 被视为 `255` (int: `0x000000FF`)。
    - `crc ^ byte` = `0x00...00` ^ `0x00...FF` = `0x000000FF`。
    - **结果**：只有低 8 位变了，高 24 位保持纯净。**这是 CRC 想要的。**

2.  **错误情况 (直接用 signed char)**：
    - `0xFF` 被视为 `-1`。
    - 提升为 int 时发生**符号位扩展**，变成 `0xFFFFFFFF`（高 24 位全被填满 1）。
    - `crc ^ byte` = `0x00...00` ^ `0xFF...FF` = `0xFFFFFFFF`。
    - **结果**：**本来只该影响低 8 位的，结果把高 24 位全部反转了！** 
    - **注意**：无论 `crc` 原本是多少（0 或 0xFFFFFFFF），异或 `0xFFFFFFFF` 都会导致高 24 位被错误反转，彻底破坏后续计算。

因此，使用 `static_cast<uint8_t>` 把它强制转换为**无符号字节**（0-255），是处理二进制数据时的标准动作。

---

## 7. 构建系统与 CMake

### 7.1 为什么选择 CMake + G++？
本项目采用 **CMake** 作为构建系统，并推荐使用 **G++ (GCC)** 作为编译器。
- **跨平台一致性**：G++ 是 Linux 环境下的标准编译器。在 Windows 上使用 G++ (MinGW-w64) 可以最大限度地模拟 Linux 的编译行为，减少因编译器差异导致的代码移植问题。
- **构建标准化**：CMake 是 C++ 界的通用标准，能够自动处理依赖管理、编译选项配置和跨平台构建脚本生成。

### 7.2 本项目的构建工具链
为了方便在 Windows 上进行类 Linux 开发，本项目配置了以下工具链：
- **编译器**：G++ (MinGW-w64 GCC 15.2.0+)
- **构建生成器**：Ninja (推荐) 或 MinGW Makefiles
- **构建脚本**：`build.ps1` (Windows PowerShell)

该脚本会自动检测系统中的 `ninja` 和 `g++`，优先构建 MinGW 环境。

### 7.3 如何搭建开发环境 (Windows)
为了获得最佳体验，建议安装 **MSYS2** 或直接下载 **MinGW-w64**。

**推荐方案 (MSYS2)**：
1. 下载并安装 [MSYS2](https://www.msys2.org/)。
2. 打开 MSYS2 UCRT64 或 MINGW64 终端，执行以下命令安装工具链：
   ```bash
   pacman -S mingw-w64-x86_64-gcc mingw-w64-x86_64-cmake mingw-w64-x86_64-ninja
   ```
3. 将 `C:\msys64\mingw64\bin` (默认路径) 添加到系统环境变量 PATH 中。

### 7.4 使用 build.ps1 构建
在项目根目录下运行：
```powershell
.\build.ps1
```
脚本会自动寻找 G++ 和 Ninja/Make 进行编译。

**构建产物路径**：
- **可执行文件**：`build/bin/` (例如 `build/bin/DistributedKV_bin.exe`)
- **静态库/存档**：`build/lib/`

若需清理并重新构建：
```powershell
.\build.ps1 --clean
```

### 7.5 运行与验证
构建完成后，你可以通过以下命令运行程序：

**1. 运行 Demo 主程序**：
```powershell
.\build\bin\DistributedKV_bin.exe
```

**2. 运行单元测试 (通过 CTest)**：
```powershell
ctest --test-dir build --output-on-failure
```

**3. 直接运行测试程序**：
```powershell
.\build\bin\skiplist_test.exe
```

### 7.6 VS Code 快捷键与集成
项目已针对 VS Code 深度优化，推荐使用以下快捷方式：

- **一键运行/调试**：按下 `F5`（会自动触发编译并运行主程序）。
- **运行单元测试**：在左侧“测试”面板点击运行，或在调试面板选择 `DistributedKV: Run SkipList Test`。
- **清理并重新配置**：`Ctrl+Shift+P` -> 输入 `CMake: Delete Cache and Reconfigure`。

---

## 8. 编码规范与文档化
 
 ### 8.1 Doxygen 注释规范
 本项目采用 Doxygen 风格的文档注释，以便于 IDE 智能提示和自动生成 API 文档。
 - **格式**：使用 `/** ... */` 开头。
 - **常用标签**：
   - `@brief`：简要描述功能。
   - `@tparam`：描述模板参数。
   - `@param`：描述函数参数。
   - `@return`：描述返回值。
 
 ---
 
 ## 9. 学习路径建议
1. **第一阶段：单机存储核心**
   - 实现一个线程安全的跳表（SkipList）。
   - 学习如何使用 `mmap` 或 `fwrite` 实现 [WAL](#10-关键术语表)。
   - 实现简单的 [SSTable](#10-关键术语表) 读取与查询。
2. **第二阶段：Raft 算法实现**
   - 编写状态机逻辑。
   - 模拟节点间的 RPC 通信（可以先在单机模拟多个线程代表不同节点）。
3. **第三阶段：网络与集成**
   - 学习 C++ 协程库（如 `asio` 或自研简单的协程调度器）。
   - 将 Raft 与 LSM-Tree 结合，实现真正的分布式 KV 存储。

---
 
 ## 10. 关键术语表
- **LSM-Tree (Log-Structured Merge-Tree)**：一种将随机写转换为顺序写的存储策略，通过内存 MemTable 和磁盘 SSTable 的多层合并实现。
- **Raft**：一种易于理解的分布式共识算法，负责在集群中达成一致性。
- **Term (任期)**：Raft 中的逻辑时间单位。
- **Commit Index**：已知已提交的最高日志索引。
- **SSTable (Sorted String Table)**：持久化在磁盘上的有序键值对文件。
- **Write-Ahead Log (WAL)**：用于崩溃恢复的顺序日志文件。
- **Log Sequence Number (LSN)/Sequence**：用于给写入操作排序的单调递增编号，重放 WAL 时用来保证回放顺序确定。
- **fsync/Sync（落盘）**：把已写入的数据从操作系统缓存尽力刷到持久化介质的操作；仅 `flush` 不等价于落盘。
- **Checksum（校验和）**：用于检测 WAL 记录损坏的校验值（如 CRC32），帮助在重放时识别坏数据或半写记录。
- **Tombstone（删除标记）**：在 LSM 系统中用“逻辑删除记录”表示删除，后续 compaction 才会真正清理数据。
- **Group Commit（组提交）**：将多条写入合并成一次 sync 落盘，以摊薄落盘开销，提升吞吐。
- **Compaction**：后台线程定期合并多个小文件，删除冗余数据。
- **Write Amplification (写入放大)**：实际写入磁盘的数据量与用户请求写入的数据量之比。在 LSM-Tree 中，由于数据需要不断在各层之间进行合并重写，会产生较大的写入放大。
- **Read Amplification (读取放大)**：为了找到一个 Key，需要查询多个文件（MemTable + 各层 SSTable）而导致的多次 I/O。
- **Space Amplification (空间放大)**：由于保留了旧版本数据或被标记删除的数据，磁盘实际占用空间大于有效数据量。
 
 ---
 
 ## 11. 项目计划（周级细化）
 
 ### 11.1 阶段 A：单机存储引擎（第 1–6 周）

**第 1 周：LSM-Tree 与 MemTable 基础**

本周目标：搭建项目骨架，理解 LSM-Tree 核心思想，并完成跳表（SkipList）的基础结构设计与空跑测试。

*   **任务一：理论预热与环境准备（已完成）**
    *   **复习**：回顾本文第 2 章与第 3 章，深入理解 LSM-Tree 的顺序写优势及跳表的选型理由。
    *   **实战**：检查 C++ 编译器（推荐 MinGW-w64 G++）与 CMake 环境，确保与 Linux 开发体验一致。
 
 *   **任务二：项目工程化搭建（已完成）**
    *   **实战**：创建项目目录结构：
         *   `src/`：源代码
         *   `include/`：头文件
         *   `tests/`：测试代码
         *   `docs/`：文档
    *   **实战**：编写根目录 `CMakeLists.txt`，配置基础编译选项（建议开启 `-std=c++20`，以及 `-Wall -g`）。
 
 *   **任务三：跳表核心数据结构设计（已完成）**
    *   **代码**：定义 `SkipList` 模板类（支持泛型 Key 和 Value）。
    *   **代码**：设计内部 `Node` 结构体：
         *   成员：`Key`, `Value`
         *   成员：`forward` 指针数组（用于指向不同层级的下一个节点）
    *   **代码**：理解并实现“最大层数”与“概率因子”常量的定义。

*   **任务四：随机层数生成与辅助函数（已完成）**
    *   **理论**：理解跳表节点高度的随机生成机制（几何分布）。
    *   **代码**：实现 `random_level()` 函数，确保生成的层数符合概率分布。
    *   **代码**：实现构造函数与析构函数，注意内存管理（使用智能指针管理节点）。

*   **任务五：核心接口声明 (API Design) (已完成)**
    *   **代码**：在头文件中完成核心功能的接口声明（暂不实现具体逻辑）：
        *   `insert(key, value)`
        *   `search(key)`
        *   `remove(key)` (注：LSM 中通常标记删除，但基础跳表可先实现物理删除)
    *   **代码**：编写一个简单的 `main.cpp`，实例化 `SkipList` 对象并调用上述空接口，确保编译通过。

*   **任务六：单元测试框架接入 (已完成)**
    *   **实战**：引入 Google Test (GTest) 库（推荐通过 CMake FetchContent 自动下载，并配置 `ghproxy.net` 镜像加速）。
    *   **实战**：编写第一个“冒烟测试”：创建一个跳表对象，断言其初始化状态（如当前层级为 0，头节点存在等）。
    *   **验收**：运行 `ctest` 或执行测试二进制文件，看到绿色的 `PASSED`。

**第 2 周：跳表核心实现与稳定性测试**

本周目标：完成跳表（SkipList）的完整增删改查（CRUD）功能，通过大规模随机测试验证正确性与内存安全性。

*   **任务一：实现核心插入逻辑 (Insert)（已完成）**
    *   **理论**：理解跳表的“寻找前驱节点”机制。在每一层中，找到小于目标 Key 的最后一个节点，记录在 `update[]` 数组中。
    *   **代码**：实现 `insert(key, value)`。
        *   步骤 1：定位插入位置，生成 `update` 路径。
        *   步骤 2：检查 Key 是否已存在。若存在，更新 Value 并返回。
        *   步骤 3：调用 `random_level()` 生成新节点高度。若新高度超过当前 `max_level`，需扩展 `update` 数组指向头节点。
        *   步骤 4：创建新节点，并逐层调整指针（`new_node->forward = prev->forward; prev->forward = new_node;`）。

*   **任务二：实现精确查找 (Search)（已完成）**
    *   **代码**：实现 `search(key)`。
    *   **逻辑**：从最高层出发，向右移动直到下一个节点大于 Key，然后下沉一层。最终在第 0 层判断下一个节点是否等于目标 Key。

*   **任务三：实现删除逻辑 (Remove)（已完成）**
    *   **代码**：实现 `remove(key)`。
    *   **逻辑**：
        *   利用 `update` 数组找到目标 Key 的所有前驱节点。
        *   逐层断开链接：`update[i]->forward[i] = target->forward[i]`。
        *   **注意**：删除后需检查是否需要降低跳表的 `current_max_level`（如果最高层只剩头节点）。
    *   **策略**：本周先以物理删除完成数据结构验收；当第 4–6 周引入 SSTable/Compaction 后，删除语义切换为 Tombstone 与 LSM 对齐。

*   **任务四：大规模随机性测试 (Stability Test)（已完成）**
    *   **实战**：编写 `tests/skiplist_test.cpp`。
    *   **测试用例 1**：顺序插入 0-10000，验证查询成功。
    *   **测试用例 2**：随机插入 10000 个乱序整数，验证查询成功。
    *   **测试用例 3**：随机删除 5000 个元素，验证剩余元素可查，已删元素查不到。
    *   **工具（可选）**：若工具链支持，可开启 AddressSanitizer (`-fsanitize=address`) 运行测试，辅助检查内存问题。
    *   **当前进度**：insert/search/remove 用例已补齐并通过（`ctest`：14/14 tests passed）。

*   **任务五：简单性能基准测试 (Benchmark)（已完成）**
    *   **实战**：编写 `examples/benchmark_skiplist.cpp`。
    *   **比较**：对比 `SkipList` 与 `std::map` (红黑树) 在 10 万级数据下的插入与读取耗时。
    *   **预期**：跳表性能应与红黑树在同一数量级（$O(\log n)$）。
    *   **结果**（Windows + MinGW g++ 15.2.0，`-O2`，`n=100000`，`reads=100000`，`seed=12345`，`max_level=16`，`p=0.5`）：

        *   SkipList insert: 37.5161 ms；read: 28.0013 ms（checksum: 4999950000）
        *   std::map insert: 16.5477 ms；read: 11.9317 ms（checksum: 4999950000）
    *   **结论**：符合“同一数量级（10^6 ops/s）”的预期，但当前实现下 `SkipList` 明显慢于 `std::map`（约 2x）。
    *   **可能原因**：跳表实现包含多层 `forward` 指针追踪、节点层数随机化与额外存储管理开销；同时本基准未控制 allocator/缓存等因素，数值更适合做相对对比而非绝对宣称。
    *   **建议**：后续想更客观可重复，可增加多轮重复取中位数、区分“顺序/随机读写”、以及在不同 `p/max_level` 下扫参数观察趋势。

**第 3 周：WAL 预写日志**

本周目标：实现最小可用的 WAL（Write-Ahead Log）顺序写入与重放恢复，让 MemTable（SkipList）在“进程崩溃后重启”场景下可被重建，并明确“写入落盘”这一语义边界。

> **必读前置知识**：在开始代码之前，请务必阅读 **[4. 持久化机制：WAL 预写日志](#4-持久化机制wal-预写日志)**，理解 WAL 的核心定义与时序要求。

*   **WAL 记录格式**
    *   **记录类型**：`Put` / `Del`（删除先作为 Tombstone 记录写 WAL，后续与 SSTable/Compaction 对齐）。
    *   **字段建议**：`checksum`、`key_len`、`value_len`、`type`、payload（key/value）。
    *   **容错策略（本周明确）**：
        *   读取遇到“尾部不完整记录”直接停止重放（认为是崩溃导致的半写）。
        *   checksum 不匹配时停止并报错（后续可扩展为跳过/隔离损坏段）。

*   **任务一：边界与目录规划（已完成）**
    *   **约束**：单进程、单线程写入；单个 WAL 文件（如 `wal.log`），不做滚动与 checkpoint。
    *   **数据目录**：确定存储目录结构（至少包含 `wal.log`），并约定启动时从该目录恢复。
    *   **验收**：已通过 `KVStoreTest.CreatesDataDirectory` 与 `DetectsExistingWAL` 测试。

*   **任务二：记录编解码与校验 (已完成)**
    *   **编码**：实现定长/变长编码方案（可选其一，但需在文档中写清楚），保证跨平台一致性（建议小端）。
    *   **校验**：实现 checksum（可从 CRC32 起步），覆盖记录头（不含 checksum 字段）与 payload。
    *   **测试**：对“编码->解码”与“校验失败”分别写单元测试。
    *   **当前进度**：已补充 `encode_log_record` 文档注释并修正 checksum 写入位置（写入记录头部 4B 预留区，避免越界）。

*   **任务三：WAL 写入（Writer）(已完成)**
    *   **追加写**：只允许 append，禁止中间修改；每条记录写入后执行 `Flush/Sync`（本周先不用 group commit）。
    *   **错误处理**：任何 I/O 失败必须向上返回错误，避免“WAL 写失败但 MemTable 仍更新”的不一致。
    *   **验收点**：写入 N 条后关闭进程（不做正常关闭流程），**数据文件完整存在，为后续恢复提供物理基础**。
    *   **实现策略**：为了保证断电数据不丢失，采用了 **Write (`fwrite`) -> Flush (`fflush`) -> Sync (`_commit/fsync`)** 的强持久化链路。此方案虽使用了 C 风格接口，但提供了比 C++ `std::ofstream` 更高的**数据持久化可靠性（Durability）**，能够防止断电导致的数据丢失。
    *   **测试结果**：`KVStoreTest.WALPersistenceCheck` 通过，验证了写入操作会实时落盘。

*   **任务四：WAL 读取与重放（Reader/Replay） (已完成)**
    *   **顺序扫描**：从头到尾读取并解析记录；遇到尾部不完整停止。
    *   **回放语义**：按 `sequence` 的顺序对 MemTable 执行 Put/Del；保证同一个 key 的多次更新能得到最后一次结果。
    *   **验收点**：重放完成后，可通过 Get 验证状态与崩溃前一致（截至最后一条完整记录）。

*   **任务五：与 MemTable（SkipList）集成，打通最小闭环（已完成）**
    *   **最小接口**：至少支持 `Put/Get/Delete`（Delete 本周实现为写 WAL + 在 MemTable 中物理删除；后续引入 SSTable 后再切换为 Tombstone 语义）。
    *   **写入路径顺序**：严格遵循 `WAL -> Sync -> MemTable`。
    *   **恢复路径**：启动时先 `Replay(WAL)` 构建 MemTable，再对外提供读写。

*   **任务六：崩溃模拟与测试用例（已完成）**
    *   **用例 1**：写入 1000 条 Put，模拟重启，验证全部可读。
    *   **用例 2**：写入 Put+Del 混合，模拟重启，验证删除语义正确。
    *   **用例 3（关键）**：构造 WAL 尾部截断（截断到任意中间位置），重启应不崩溃，且恢复到最后一条完整记录为止。
    *   **用例 4（关键）**：构造 checksum 损坏，重放应返回明确错误（或按约定策略停止并提示原因）。
    *   **对应测试**：`WALReplayTest.BulkRecovery1000` / `WALReplayTest.MixedPutDelRecovery` / `WALReplayTest.TruncateMidRecord` / `WALReplayTest.CorruptMiddleRecordStopsAtPrefix`

*   **验收标准**
    *   能通过 WAL 重放重建 MemTable（无需 SSTable 参与）。
    *   “尾部不完整写入”可容忍，不崩溃，且恢复结果可解释（截至最后一条完整记录）。
    *   checksum 损坏可被检测到，并有明确的失败表现（错误码/异常/日志三选一，但需一致）。

**第 4 周：SSTable 文件格式与 Flush 流程**

本周目标：设计并实现 SSTable（Sorted String Table）的磁盘文件格式，完成从内存 MemTable 到磁盘文件的 Flush 流程，初步实现“分层存储”的雏形。

*   **任务一：SSTable 物理布局设计 (On-Disk Layout)**
    *   **理论**：理解 SSTable 的**不可变性 (Immutable)** 与 **有序性**。SSTable 一旦生成，永远不会被修改，只能被删除（Compaction 时）。
    *   **设计 (Block-based)**：
        *   **Data Block**：将数据按固定大小（如 4KB）切分，Block 内部有序存储 KV。Block 是 I/O 的最小单元。
        *   **Meta Block (Index)**：记录每个 Data Block 的 **Last Key**（该块最大 Key）与 **Offset**（文件偏移量），用于快速定位 Key 所在的 Block。
        *   **Footer**：文件末尾的定长区域（如 48 字节），记录 Index Block 的 Offset、Size 以及文件魔数 (Magic Number)。
    *   **产出**：在 `docs/format.md` 或头文件中明确字节级布局。

*   **任务二：SSTable 构造器 (Builder)**
    *   **类设计**：`SSTableBuilder`
    *   **核心逻辑**：
        *   `Add(key, value)`：接收来自 MemTable 的有序 KV 对。
        *   **Buffer 管理**：在内存中缓存数据，当达到 Block Size 阈值时，打包成 Block 写入磁盘，并计算 Checksum（CRC32）。
        *   **Index 构建**：每写入一个 Data Block，在内存中记录其 `Last Key` 和 `Offset`。
        *   `Finish()`：将内存中的 Index 数据写入文件，最后写入 Footer，关闭文件。
    *   **验收**：编写单元测试，手动构造 KV 调用 Builder，生成一个 `.sst` 文件，检查文件大小是否符合预期。

*   **任务三：SSTable 读取器 (Reader & Iterator)**
    *   **类设计**：`SSTable` (Reader)
    *   **核心逻辑**：
        *   `Open(file_path)`：打开文件，读取末尾 Footer，根据 Footer 信息读取并解析 Index Block。
        *   `NewIterator()`：提供类似 MemTable 的迭代器接口 (`Seek`, `Valid`, `Key`, `Value`, `Next`)。
        *   **查找优化**：在 `Seek(key)` 时，先在 Index Block 中**二分查找**定位到目标 Data Block，再读取该 Block 并在其内部查找。
    *   **验收**：读取任务二生成的 `.sst` 文件，验证所有 KV 能被正确读出，且顺序正确。

*   **任务四：集成 Flush (MemTable -> SSTable)**
    *   **代码**：在 `KVStore` 中增加 `Flush` 逻辑。
    *   **流程**：
        1.  **触发**：当 MemTable 占用内存达到阈值（如 2MB）。
        2.  **冻结**：将当前 MemTable 标记为 Immutable，并创建一个新的 MemTable 接收新写入。
        3.  **Dump**：遍历 Immutable MemTable，调用 `SSTableBuilder` 将其序列化为磁盘上的 `L0_001.sst` 文件。
        4.  **清理**：Flush 成功后，清空 Immutable MemTable，并**删除对应的 WAL 文件**（因为数据已持久化到 SSTable）。
    *   **注意**：本周暂不实现 Manifest（元数据管理），只需简单用文件名管理（如递增 ID）。

*   **任务五：单元测试与验证**
    *   **测试用例 1 (SSTable 读写)**：写入 10000 条数据，Flush 成文件，重新 Open 并校验数据完整性。
    *   **测试用例 2 (Block 边界)**：构造跨 Block 的数据（例如 Key 刚好在 Block 边界），验证查找正确性。
    *   **测试用例 3 (重启持久化)**：写入数据 -> Flush -> 模拟重启 -> 仅从 SSTable 读取（本周 Get 接口可能还未完全打通，可用 Iterator 验证）。

**第 5 周：查询路径打通**
- 学习内容：读路径分层（MemTable + SSTable）
- 开发任务：实现 Get 查询链路，先查 MemTable，再查 SSTable
- 验收标准：同时覆盖内存与磁盘数据的查询正确性

**第 6 周：Compaction 合并**
- 学习内容：分层合并策略、重复键处理
- 开发任务：实现基础 Compaction 流程
- 验收标准：磁盘文件数量可控，旧数据正确被淘汰

### 11.2 阶段 B：Raft 共识协议（第 7–12 周）

**第 7 周：Raft 状态机框架**
- 学习内容：Leader/Follower/Candidate 状态转移
- 开发任务：实现 Raft 状态机骨架与超时机制
- 验收标准：单机多线程模拟选举流程

**第 8 周：日志复制**
- 学习内容：AppendEntries 原理与心跳机制
- 开发任务：实现日志同步与心跳
- 验收标准：Leader 写入后 follower 日志保持一致

**第 9 周：日志冲突处理**
- 学习内容：日志对齐与冲突回滚
- 开发任务：实现冲突条目回滚逻辑
- 验收标准：节点恢复后日志可自动对齐

**第 10 周：提交与一致性保证**
- 学习内容：Commit Index 推进与安全性
- 开发任务：实现提交逻辑
- 验收标准：多数派确认后才对外可见

**第 11 周：快照机制**
- 学习内容：Snapshot 保存与恢复
- 开发任务：实现快照生成与加载接口
- 验收标准：节点重启后可通过快照快速恢复

**第 12 周：Raft 测试与故障注入**
- 学习内容：分布式故障模拟方法
- 开发任务：实现故障注入脚本与测试场景
- 验收标准：Leader 崩溃后系统仍可完成选举

### 11.3 阶段 C：网络层与集成（第 13–16 周）

**第 13 周：RPC 通信框架**
- 学习内容：异步 IO、序列化协议
- 开发任务：实现基础 RPC 调用
- 验收标准：节点之间可完成心跳通信

**第 14 周：Raft 与存储层集成**
- 学习内容：状态机与存储引擎的绑定
- 开发任务：实现 Put/Get 请求经 Raft 提交后落盘
- 验收标准：多节点数据一致

**第 15 周：读写性能优化**
- 学习内容：批量写、读缓存策略
- 开发任务：引入批量写入与基础读缓存
- 验收标准：吞吐提升，延迟降低

**第 16 周：集群稳定性测试**
- 学习内容：系统性故障测试设计
- 开发任务：模拟断网、节点崩溃、重启
- 验收标准：系统保持强一致性

### 11.4 阶段 D：工程化与展示（第 17–20 周）

**第 17 周：代码结构与工程化整理**
- 学习内容：模块化设计与目录规范
- 开发任务：整理模块划分与构建脚本
- 验收标准：新开发者可快速理解结构

**第 18 周：性能压测报告**
- 学习内容：基准测试方法
- 开发任务：产出读写性能曲线与测试报告
- 验收标准：性能曲线清晰可复现

**第 19 周：一致性验证**
- 学习内容：正确性测试方法
- 开发任务：构建一致性验证脚本
- 验收标准：多次重复测试无一致性错误

**第 20 周：成果打包与演示**
- 学习内容：项目表达与演示技巧
- 开发任务：编写 Demo 流程与说明材料
- 验收标准：能完整展示项目核心价值

### 11.5 每周投入建议
- 建议每周 12–20 小时投入
- 若每周少于 10 小时，总周期可能延长至 6 个月以上

---

## 12. 测试与验证（详见独立文档）

本项目的完整测试指南、测试用例清单及历史验收记录已迁移至独立文档：

👉 **[DistributedKV 测试记录文档 (Test_Record.md)](./Test_Record.md)**

该文档包含：
1.  **测试体系概览**：GTest/CTest 的使用方法与 AAA 测试套路。
2.  **测试用例清单**：各模块（SkipList, KVStore, WAL）的核心测试点说明。
3.  **历史测试记录**：每周任务的详细验收状态与结果汇总。
